{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNcUqwcOVNJxdIANWcEZpxa"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"5ghURjbssf6h"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import os\n","import cv2\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import img_to_array, ImageDataGenerator\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n","from tensorflow.keras.utils import to_categorical\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","\n","# File paths\n","train_csv_path = 'Train.csv'\n","test_csv_path = 'Test.csv'\n","meta_csv_path = 'Meta.csv'\n","train_images_dir = 'Train/'  # Directory containing training images\n","test_images_dir = 'Test/'    # Directory containing test images\n","\n","# Load CSV files\n","train_df = pd.read_csv(train_csv_path)\n","test_df = pd.read_csv(test_csv_path)\n","meta_df = pd.read_csv(meta_csv_path)\n","\n","# Load and preprocess data\n","def load_data(df, images_dir):\n","    images = []\n","    labels = []\n","    for _, row in df.iterrows():\n","        img_path = os.path.join(images_dir, row['Path'])\n","        if os.path.isfile(img_path):\n","            img = cv2.imread(img_path)\n","            img = cv2.resize(img, (64, 64))  # Resize to match input size\n","            img = img_to_array(img)\n","            img = img / 255.0  # Normalize the image\n","            images.append(img)\n","            labels.append(row['ClassId'])\n","    return np.array(images), np.array(labels)\n","\n","# Load training and test data\n","train_images, train_labels = load_data(train_df, train_images_dir)\n","test_images, test_labels = load_data(test_df, test_images_dir)\n","\n","# Convert labels to one-hot encoding\n","num_classes = len(np.unique(train_labels))\n","train_labels = to_categorical(train_labels, num_classes=num_classes)\n","test_labels = to_categorical(test_labels, num_classes=num_classes)\n","\n","# Split data for validation\n","X_train, X_val, y_train, y_val = train_test_split(train_images, train_labels, test_size=0.2, random_state=42)\n","\n","# Define the CNN model\n","model = Sequential([\n","    Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)),\n","    MaxPooling2D(pool_size=(2, 2)),\n","    Conv2D(64, (3, 3), activation='relu'),\n","    MaxPooling2D(pool_size=(2, 2)),\n","    Conv2D(128, (3, 3), activation='relu'),\n","    MaxPooling2D(pool_size=(2, 2)),\n","    Flatten(),\n","    Dense(128, activation='relu'),\n","    Dense(num_classes, activation='softmax')\n","])\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# Train the model\n","history = model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val), batch_size=32)\n","\n","# Save the model\n","model.save('traffic_sign_model.h5')\n","\n","# Evaluate the model\n","loss, accuracy = model.evaluate(test_images, test_labels)\n","print(f'Test Accuracy: {accuracy:.4f}')\n","\n"]},{"cell_type":"code","source":["# Function to preprocess and predict the traffic sign\n","def predict_traffic_sign(image_path):\n","    # Load and preprocess the image\n","    img = cv2.imread(image_path)\n","    img = cv2.resize(img, (64, 64))  # Resize to match input size\n","    img = img_to_array(img)\n","    img = img / 255.0  # Normalize the image\n","    img = np.expand_dims(img, axis=0)  # Add batch dimension\n","\n","    # Predict the class\n","    prediction = model.predict(img)\n","    class_id = np.argmax(prediction, axis=1)[0]\n","\n","    return class_id\n","\n","# Example usage\n","image_path = 'path/to/your/image.png'  # Update with the path to your image\n","predicted_class_id = predict_traffic_sign(image_path)\n","\n","print(f'Predicted Class ID: {predicted_class_id}')"],"metadata":{"id":"ma7oA1bm8clH"},"execution_count":null,"outputs":[]}]}